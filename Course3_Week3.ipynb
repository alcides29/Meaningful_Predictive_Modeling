{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3: Validating Data and Predictive Pipelines\n",
    "#### Making Meaningful Predictions from Data\n",
    "\n",
    "This week we were introduced to the concept of validation and pipelines. In this notebook, we will go over basic training, testing, and validating data and move on to some pipeline practice as shown in lecture videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Training, Validating, Testing\n",
    "1. **Training datasets** form the basis of a model's learning, teaching it how to estimate its output.\n",
    "2. **Validation datasets** check the accuracy, quality, and integrity of a model, as well as fine-tuning any parameters that are not directly optimized.\n",
    "3. **Test datasets** are usually what we are most interested in -- how does the model perform with previously unseen data that reflects real-world cases?\n",
    "\n",
    "To learn more about the difference between these, click here: https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7\n",
    "\n",
    "A good model is one that generalizes to new data! If a model performs well on a training set but not on new data, then it is probably **overfitting** the training data.\n",
    "\n",
    "#### \"Theorems\" about these sets\n",
    "\n",
    "* The training error increases as lambda increases\n",
    "* The validation and test error are at least as large as the training error (assuming infinitely large random partitions)\n",
    "* The validation/test error will usually have a “sweet spot” between under- and over-fitting\n",
    "\n",
    "### The Data\n",
    "\n",
    "Unzip the `reviews.json` file in the Week 2 folder. This dataset contains 25,000 Yelp reviews of various businesses. For this notebook, we will be looking at how well various words can predict a business' rating.\n",
    "\n",
    "### Reading the Data\n",
    "First we import a few libraries. Most of these are the same as before, though a few new libraries are included for string processing. \n",
    "\n",
    "Then, specify the path of the file. You may need to change the given path according to your local environment. This should be familiar if you took Course 1 (*Basic Data Ingestion, Processing, and Visualization*) of the Python Data Products specialization already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import string # Some string utilities\n",
    "import random\n",
    "from nltk.stem.porter import PorterStemmer # Stemming\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./datasets/reviews.json\"\n",
    "f = open(path, 'rt', encoding=\"utf8\")\n",
    "\n",
    "# Load in JSON file\n",
    "dataset = []\n",
    "for i in range(25000):\n",
    "    dataset.append(json.loads(f.readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_id': 'QScdf32LViCASQirYGJ6hA',\n",
       " 'user_id': 'ZnZmF11O42qfhhNNA5juhA',\n",
       " 'business_id': 'XHYxwXtnidQsm89rE_OIUQ',\n",
       " 'stars': 5.0,\n",
       " 'useful': 0,\n",
       " 'funny': 0,\n",
       " 'cool': 0,\n",
       " 'text': \"WOW!! This company is amazing!!!!! As a full time working mom I can't tell you how hard it is to keep up with keeping the house clean. I am a neat freak and they came in and made my house so spotless. It is such a breath of fresh air coming home and knowing I don't have to worry about anything! My house is so shiny and it even smelled good! You guys did a fantastic job and we will definitely be contacting you again! This cleaning came at the perfect time and the cleaning ladies were so nice and friendly! Thank you so much! You have made a life long customer!\",\n",
       " 'date': '2016-11-22 01:48:06'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at first entry in dataset\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Examine Our Dataset\n",
    "#### Counting Number of Unique Words\n",
    "Before we start analyzing this data, let's see how many unique words we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119350\n"
     ]
    }
   ],
   "source": [
    "# Count total unique words\n",
    "wordCount = defaultdict(int)\n",
    "for d in dataset:\n",
    "    for w in d['text'].split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "print(len(wordCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of words! This number of words is too many to deal with (i.e., it would result in a 119,350 dimensional feature vector if used naively). Let's try to reduce this by removing punctuation and capitalization, so that two instances of the same word will be counted as being the same even if punctuated or capitalized differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52202\n"
     ]
    }
   ],
   "source": [
    "# Count total unique words, ignoring punctuation and capitalization\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in dataset:\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "print(len(wordCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're still left with a large number of words, so possibly we can reduce this number of words further if we treat different word inflections (e.g. \"drinks\" vs. \"drinking\") as being instances of the same word, by identifying their word stem (i.e., \"drink\"). This process is called \"stemming\".\n",
    "We perform stemming using a stemmer from the NLTK (Natural Language Toolkit) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39547\n"
     ]
    }
   ],
   "source": [
    "# Count total unique words, ignoring punctuation and capitalization and using stemming.\n",
    "# This one might take a bit of time to run -- be patient!\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "stemmer = PorterStemmer() # object doing the stemming\n",
    "for d in dataset:\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        w = stemmer.stem(w) # with stemming\n",
    "        wordCount[w] += 1\n",
    "\n",
    "print(len(wordCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting and Building Features from the Most Common Words\n",
    "That's still a lot of words. One way to deal with this is to take the most common words and build features out of those.\n",
    "\n",
    "First we build a few data structures to count the number of instances of each word. Here we remove punctuation and capitalization, but do not apply stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total unique words, ignoring punctuation and capitalization\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in dataset:\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422\n"
     ]
    }
   ],
   "source": [
    "print(wordCount['wow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having counted the number of instances of each word, we can sort them to find the most common, and build a word index based on these frequencies. For example, the most frequent word will have index 0, the secont most frequent will have index 1, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse() # Most frequent = index 0\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "# Assign the index 0 to 999 to the most 1000 frecuent words\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building our Bag-of-Words Feature Representation\n",
    "Now that we have our dictionary of common words, we can now build a feature vector by counting how often each of these words appears in each review. This is called a **\"bag-of-words\" feature representation**. This results in a 1,000 dimensional feature vector (1,001 if we include an offset term)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for building bag-of-words\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in wordSet:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Build Training Dataset\n",
    "We will build our training set by doing the following:\n",
    "1. Shuffle entries\n",
    "2. Define `X` - matrix of features\n",
    "3. Define `y` - the outcomes\n",
    "4. Perform least squares regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature(d) for d in dataset] # using the bag-of-words function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of stars\n",
    "y = [d['stars'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta,residuals,rank,s = numpy.linalg.lstsq(X, y,rcond=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Visualize Important Words\n",
    "Once the model has finished training, we can examine which are the most positive (or negative) words by looking at the largest (or smallest) corresponding values for theta To do so, let's sort our words based on their corresponding weights from `theta`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordWeights = list(zip(theta, words + ['offset']))\n",
    "wordWeights.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.7553245155694405, 'worst'),\n",
       " (-0.7389947690060996, 'horrible'),\n",
       " (-0.6005449383926081, 'terrible'),\n",
       " (-0.5290251025492264, 'rude'),\n",
       " (-0.5215853670104253, 'poor'),\n",
       " (-0.48335065677884526, 'bland'),\n",
       " (-0.48050793069310815, 'awful'),\n",
       " (-0.46231447378886875, 'overpriced'),\n",
       " (-0.4612443829370413, 'disappointing'),\n",
       " (-0.3204898819445335, 'dirty')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 most negative words\n",
    "wordWeights[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.25074180901827475, 'best'),\n",
       " (0.27105294896173754, 'reasonable'),\n",
       " (0.2738341202875696, 'above'),\n",
       " (0.2755221615166824, 'professional'),\n",
       " (0.3063027581586344, 'awesome'),\n",
       " (0.311010709377801, 'amazing'),\n",
       " (0.31354368728813614, 'excellent'),\n",
       " (0.3153643923320738, 'pleased'),\n",
       " (0.31900508815656037, 'outstanding'),\n",
       " (3.642246589684552, 'offset')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9 most positive words (10th is offset term)\n",
    "wordWeights[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d. Include Regularizer\n",
    "**Regularization** is the process of penalizing model complexity during training. In this case, though the above model was effective, it was also very high dimensional, and thus may have been prone to **overfitting**. We can try to address this by adding a regularizer to our model.\n",
    "\n",
    "The \"Ridge\" class from `sklearn` implements a least squares regression model (as in our example above) that includes a regularizer. The strength of the regularizer is controlled by the parameter `alpha` (equivalent to `lambda` in the course lectures). Otherwise, fitting the ridge regression model is exactly the same as fitting a regular least squares model! \n",
    "\n",
    "Here is the method call we are using: `model = linear_model.Ridge(1.0, fit_intercept=False)`\n",
    "\n",
    "**Note the two extra parameters:** The first is the regularization strength (`alpha`). The second indicates we do not want the model to fit an intercept (since our feature vector already includes one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Ridge in module sklearn.linear_model._ridge:\n",
      "\n",
      "class Ridge(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, _BaseRidge)\n",
      " |  Ridge(alpha=1.0, *, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver='auto', random_state=None)\n",
      " |  \n",
      " |  Linear least squares with l2 regularization.\n",
      " |  \n",
      " |  Minimizes the objective function::\n",
      " |  \n",
      " |  ||y - Xw||^2_2 + alpha * ||w||^2_2\n",
      " |  \n",
      " |  This model solves a regression model where the loss function is\n",
      " |  the linear least squares function and regularization is given by\n",
      " |  the l2-norm. Also known as Ridge Regression or Tikhonov regularization.\n",
      " |  This estimator has built-in support for multi-variate regression\n",
      " |  (i.e., when y is a 2d-array of shape (n_samples, n_targets)).\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <ridge_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  alpha : {float, ndarray of shape (n_targets,)}, default=1.0\n",
      " |      Regularization strength; must be a positive float. Regularization\n",
      " |      improves the conditioning of the problem and reduces the variance of\n",
      " |      the estimates. Larger values specify stronger regularization.\n",
      " |      Alpha corresponds to ``1 / (2C)`` in other linear models such as\n",
      " |      :class:`~sklearn.linear_model.LogisticRegression` or\n",
      " |      :class:`sklearn.svm.LinearSVC`. If an array is passed, penalties are\n",
      " |      assumed to be specific to the targets. Hence they must correspond in\n",
      " |      number.\n",
      " |  \n",
      " |  fit_intercept : bool, default=True\n",
      " |      Whether to fit the intercept for this model. If set\n",
      " |      to false, no intercept will be used in calculations\n",
      " |      (i.e. ``X`` and ``y`` are expected to be centered).\n",
      " |  \n",
      " |  normalize : bool, default=False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      " |      on an estimator with ``normalize=False``.\n",
      " |  \n",
      " |  copy_X : bool, default=True\n",
      " |      If True, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  max_iter : int, default=None\n",
      " |      Maximum number of iterations for conjugate gradient solver.\n",
      " |      For 'sparse_cg' and 'lsqr' solvers, the default value is determined\n",
      " |      by scipy.sparse.linalg. For 'sag' solver, the default value is 1000.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Precision of the solution.\n",
      " |  \n",
      " |  solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'},         default='auto'\n",
      " |      Solver to use in the computational routines:\n",
      " |  \n",
      " |      - 'auto' chooses the solver automatically based on the type of data.\n",
      " |  \n",
      " |      - 'svd' uses a Singular Value Decomposition of X to compute the Ridge\n",
      " |        coefficients. More stable for singular matrices than 'cholesky'.\n",
      " |  \n",
      " |      - 'cholesky' uses the standard scipy.linalg.solve function to\n",
      " |        obtain a closed-form solution.\n",
      " |  \n",
      " |      - 'sparse_cg' uses the conjugate gradient solver as found in\n",
      " |        scipy.sparse.linalg.cg. As an iterative algorithm, this solver is\n",
      " |        more appropriate than 'cholesky' for large-scale data\n",
      " |        (possibility to set `tol` and `max_iter`).\n",
      " |  \n",
      " |      - 'lsqr' uses the dedicated regularized least-squares routine\n",
      " |        scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative\n",
      " |        procedure.\n",
      " |  \n",
      " |      - 'sag' uses a Stochastic Average Gradient descent, and 'saga' uses\n",
      " |        its improved, unbiased version named SAGA. Both methods also use an\n",
      " |        iterative procedure, and are often faster than other solvers when\n",
      " |        both n_samples and n_features are large. Note that 'sag' and\n",
      " |        'saga' fast convergence is only guaranteed on features with\n",
      " |        approximately the same scale. You can preprocess the data with a\n",
      " |        scaler from sklearn.preprocessing.\n",
      " |  \n",
      " |      All last five solvers support both dense and sparse data. However, only\n",
      " |      'sag' and 'sparse_cg' supports sparse input when `fit_intercept` is\n",
      " |      True.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Used when ``solver`` == 'sag' or 'saga' to shuffle the data.\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         `random_state` to support Stochastic Average Gradient.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      " |      Weight vector(s).\n",
      " |  \n",
      " |  intercept_ : float or ndarray of shape (n_targets,)\n",
      " |      Independent term in decision function. Set to 0.0 if\n",
      " |      ``fit_intercept = False``.\n",
      " |  \n",
      " |  n_iter_ : None or ndarray of shape (n_targets,)\n",
      " |      Actual number of iterations for each target. Available only for\n",
      " |      sag and lsqr solvers. Other solvers will return None.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  RidgeClassifier : Ridge classifier\n",
      " |  RidgeCV : Ridge regression with built-in cross validation\n",
      " |  :class:`sklearn.kernel_ridge.KernelRidge` : Kernel ridge regression\n",
      " |      combines ridge regression with the kernel trick\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.linear_model import Ridge\n",
      " |  >>> import numpy as np\n",
      " |  >>> n_samples, n_features = 10, 5\n",
      " |  >>> rng = np.random.RandomState(0)\n",
      " |  >>> y = rng.randn(n_samples)\n",
      " |  >>> X = rng.randn(n_samples, n_features)\n",
      " |  >>> clf = Ridge(alpha=1.0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Ridge()\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Ridge\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      _BaseRidge\n",
      " |      sklearn.linear_model._base.LinearModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, alpha=1.0, *, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver='auto', random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit Ridge regression model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training data\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_targets)\n",
      " |          Target values\n",
      " |      \n",
      " |      sample_weight : float or ndarray of shape (n_samples,), default=None\n",
      " |          Individual weights for each sample. If given a float, every sample\n",
      " |          will have the same weight.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a\n",
      " |          precomputed kernel matrix or a list of generic objects instead,\n",
      " |          shape = (n_samples, n_samples_fitted),\n",
      " |          where n_samples_fitted is the number of\n",
      " |          samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The R2 score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(linear_model.Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(fit_intercept=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the coefficients learned by our new regularized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordWeights = list(zip(theta, words + ['offset']))\n",
    "wordWeights.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.7542478890211587, 'worst'),\n",
       " (-0.7380238948354727, 'horrible'),\n",
       " (-0.599797208223169, 'terrible'),\n",
       " (-0.5286441442036913, 'rude'),\n",
       " (-0.5206526415790933, 'poor'),\n",
       " (-0.4825422166824396, 'bland'),\n",
       " (-0.47937265073127644, 'awful'),\n",
       " (-0.46085368280583106, 'overpriced'),\n",
       " (-0.4598062746402599, 'disappointing'),\n",
       " (-0.3197940121855995, 'dirty')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 most negative words\n",
    "wordWeights[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.25089466451190334, 'best'),\n",
       " (0.2707656635951775, 'reasonable'),\n",
       " (0.2731925133263086, 'above'),\n",
       " (0.2753692315324256, 'professional'),\n",
       " (0.3063121371505928, 'awesome'),\n",
       " (0.3111185632380554, 'amazing'),\n",
       " (0.3135411208752749, 'excellent'),\n",
       " (0.3142912016174834, 'pleased'),\n",
       " (0.3182140602718254, 'outstanding'),\n",
       " (3.6416051508951517, 'offset')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9 most positive words (10th is offset term)\n",
    "wordWeights[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Regression Diagnostics: MSE and R^2 Review\n",
    "Let's step away from programming for a moment. How do we evaluate our regressors? This section should be familiar from Week 1 of this course.\n",
    "\n",
    "### 2a. MSE (Mean Squared Error)\n",
    "What is the MSE (which we have already been using) and its relationship to the R^2 statistic? We start by extracting the predictions from our model and computing their squared differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = [(x-y)**2 for (x,y) in zip(predictions,y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **MSE** is just the average (mean) of these squared differences, which we can compute with a few trivial Python commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.9237226689725578\n"
     ]
    }
   ],
   "source": [
    "MSE = sum(differences) / len(differences)\n",
    "print(\"MSE = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. R^2\n",
    "As we saw in the lectures, the **R^2** (and the **FVU**, or \"Fraction of Variance Unexplained\") normalize the **Mean Squared Error** based on the variance of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.5582919710243426\n"
     ]
    }
   ],
   "source": [
    "FVU = MSE / numpy.var(y)\n",
    "R2 = 1 - FVU\n",
    "print(\"R2 = \" + str(R2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Predictive Pipelines\n",
    "\n",
    "In its most basic form, a pipeline links steps together. In machine learning and data science, pipelines allow you transform data from one representation to another through a series of steps. \n",
    "\n",
    "A lower-level example can be found in Unix, where you can *pipeline* the *output* of some command as an *input* some other command with the `|` (e.g. `cat words.txt | wc -c` will result in the number of characters in `words.txt`). In this notebook, we will implement a regularization pipeline to help us train, test, and validate data, where (as stated before) **regularization** is the process of penalizing model complexity during training.\n",
    "\n",
    "Let's import libraries and read our dataset in again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./datasets/reviews.json\"\n",
    "f = open(path, 'rt', encoding=\"utf8\")\n",
    "\n",
    "# Load in JSON file\n",
    "dataset = []\n",
    "for i in range(25000):\n",
    "    dataset.append(json.loads(f.readline()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Rebuild Common Word Features\n",
    "This is identical to what we did in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "for d in dataset:\n",
    "  r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "  for w in r.split():\n",
    "    wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse() # Highest frequency = index 0\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-words function\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Build the Validation Set\n",
    "Again we split our data, but this time we split it into _three_ parts - a training, a validation, and a test component. Recall that validation sets check the accuracy, quality, and integrity of a model, as well as fine-tuning any parameters that are not directly optimized.\n",
    "\n",
    "Let's shuffle the dataset and define `X` and `y` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(dataset)\n",
    "X = [feature(d) for d in dataset]\n",
    "y = [d['stars'] for d in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll use half of our data (and labels) for **training**, the next quarter for **validation**, and the final quarter for **testing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(X)\n",
    "\n",
    "X_train = X[:N//2]\n",
    "X_valid = X[N//2:3*N//4]\n",
    "X_test = X[3*N//4:]\n",
    "\n",
    "y_train = y[:N//2]\n",
    "y_valid = y[N//2:3*N//4]\n",
    "y_test = y[3*N//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 12500, 6250, 6250)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine size of data\n",
    "len(X), len(X_train), len(X_valid), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Train the Model\n",
    "Again we'll train a model based on regularized (Ridge) regression. Our MSE function is the same as before, but this time for convience takes an (already trained) model as an input parameter.\n",
    "\n",
    "#### Finally, to implement the pipeline, we:\n",
    "1. Iterate through various values of lambda\n",
    "2. Fit a ridge regression model for each of these values\n",
    "3. Evaluate the performance of this model on the validation set\n",
    "4. Keep track of which model is the best we've seen so far (on the validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find Mean Squared Error\n",
    "def MSE(model, X, y):\n",
    "    predictions = model.predict(X)\n",
    "    differences = [(a-b)**2 for (a,b) in zip(predictions, y)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to keep track of the current best model and MSE\n",
    "bestModel = None \n",
    "bestMSE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.01, training/validation error = 0.8859307244937737/1.0338668358221885\n",
      "lambda = 0.1, training/validation error = 0.8859307614562422/1.033803122385432\n",
      "lambda = 1, training/validation error = 0.8859344222423866/1.0331742829485744\n",
      "lambda = 10, training/validation error = 0.8862683501645673/1.0276417170854784\n",
      "lambda = 100, training/validation error = 0.9038071605516236/1.010919641939276\n"
     ]
    }
   ],
   "source": [
    "# Train and fine-tune model with training and validation sets\n",
    "for lamb in [0.01, 0.1, 1, 10, 100]:\n",
    "    model = linear_model.Ridge(lamb, fit_intercept=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    mseTrain = MSE(model, X_train, y_train)\n",
    "    mseValid = MSE(model, X_valid, y_valid)\n",
    "    \n",
    "    print(\"lambda = \" + str(lamb) + \", training/validation error = \" +\n",
    "          str(mseTrain) + '/' + str(mseValid))\n",
    "    if not bestModel or mseValid < bestMSE:\n",
    "        bestModel = model\n",
    "        bestMSE = mseValid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the performance of our best model on the **test** set. Note that this is the only time throughout the entire pipeline that we examine the test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error = 1.0562907279809801\n"
     ]
    }
   ],
   "source": [
    "mseTest = MSE(bestModel, X_test, y_test)\n",
    "print(\"test error = \" + str(mseTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## You're all done!\n",
    "You should be familiar with the basics of training, validating, and testing in Python by now. We encourage you to explore further by using your own datasets and thinking about research questions you can answer with pipelines. You will have a chance to show off your skills at the end of this course with your very own project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
